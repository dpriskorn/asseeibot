@startuml
'https://plantuml.com/class-diagram

'BaseModel is not included in the hierarchy

abstract class BaseModel

package Identifiers {
    abstract class Identifier
    {
    +value: str
    -__str__()
    }
    class Doi
    {
    +regex_validated: bool = True
    +wikidata_scientific_item: WikidataScientificItem = None
    -__str__()
    -__test_doi__()
    +lookup_in_crossref_and_then_in_wikidata()
    }
}



package PickledDataframe {
    abstract class PickledDataframe
    {
    -_pickle_filename: str
    +dataframe: DataFrame = None
    +match: FuzzyMatch = None
    -__read_dataframe_from_disk__()
    -__save_dataframe_to_disk__()
    -__verify_that_the_cache_file_exists_and_read__()
    }

    class Matches
    {
    +crossref_subject: str = None
    +crossref_subject_found: bool = None
    +pickle: str = config.cache_pickle_filename
    +qid_dropped: bool = None
    +qid_found: bool = None

    -__append_match_result_to_the_dataframe__()
    -__check_crossref_subject__()
    -__check_if_drop_was_successful__()
    -__check_qid__()
    -__drop_qid_from_dataframe__()
    -__extract_match__()
    -__lookup_crossref_subject__()
    -__validate_match_variables__()
    +add()
    +delete()
    +read()
    }

    class Statistics
    {
    -__pickle: str = config.statistic_pickle_filename
    -__append_to_the_dataframe__()
    +add()
    }
}

package ontology_based_ner_matcher {
    class FuzzyMatch
    {
    +alias: Optional[str]
    +approved: Optional[bool]
    +crossref_subject: Optional[str]
    +description: Optional[str]
    +edited_qid: Optional[EntityId]
    +label: Optional[str]
    +match_based_on: Optional[MatchBasedOn]
    +original_subject: Optional[str]
    +qid: Optional[EntityId]
    +split_subject: Optional[bool]
    -__str__()
    }

    class OntologyBasedNerMatcher
    {
    +crossref_subject: str
    +match: Optional[FuzzyMatch] = None
    +original_subject: str
    +split_subject: bool
    -__check_subject_and_original_subject__()
    -__calculate_scores__()
    -__enrich_cache_match__()
    -__extract_top_match_score__()
    -__extract_top_label_match_and_score__()
    -__extract_top_alias_match_and_score__()
    -__extract_top_matches__()
    -__get_first_row__()
    -__get_the_dataframe_from_config__()
    -__get_top_match__()
    -__lookup_in_cache__()
    -__lookup_scores_and_matches_in_the_ontology__()
    -__print_dataframe_head__()
    -__print_subject_information__()
    -__sort_dataframe__()
    -__validate_the_match__()
    +lookup_subject()
    }
}

package Wikimedia {
    package Wikidata {
        class EntityId
        {
        +letter: WikidataNamespaceLetters = None
        +raw_entity_id: str
        +rest: str = None
        +value
        -__post_init_post_parse__()
        -__str__()
        +history_url()
        +url()
        }

        abstract class Item
        {
        -__aliases: Optional[List[str]]
        -__description: Optional[str]
        -__item: Optional[EntityItem]
        +qid: EntityId
        +aliases()
        +description()
        -__fetch__()
        }

        class ScientificItem
        {
        +crossref: CrossrefEngine = None
        +crossref_doi: str = None
        +doi_found_in_crossref: bool = False
        +doi_found_in_wikidata: bool = False
        +number_of_subject_matches: int = 0
        +qid: EntityId = None
        +subject_matches: List[FuzzyMatch] = None
        +wikipedia_doi: str  # This is mandatory
        -__call_the_hub_api__()
        -__lookup_via_hub__()
        -__lookup_in_crossref__()
        -__upload_main_subject_using_wbi__()
        -__lookup_in_wikidata__()
        +lookup_and_match_subjects()
        +upload_subjects()
        +wikidata_doi_search_url()
        }
    }

    package Wikipedia {
        package templates {
            package enwp {

                class CiteJournal
                {
                +doi: Optional[str] = None
                +journal_title: str = None
                +jstor: str = None
                +pmid: str = None
                +scopus_id: str = None
                -__str__()
                }
            }
        }

        class WikipediaPage
        {
        -_pywikibot_page: Page = None
        +dois: List[Doi] = None
        +missing_dois: List[Doi] = None
        +number_of_dois: int = 0
        +number_of_isbns: int = 0
        +number_of_missing_dois: int = 0
        +number_of_missing_isbns: int = 0
        +page_id: int = None
        +references: List[WikipediaPageReference] = None
        +title: str = None
        +wikimedia_event: Any = None
        -__calculate_statistics__()
        -__get_title_from_event__()
        -__get_wikipedia_page__()
        -__match_subjects__()
        -__parse_templates__()
        -__populate_missing_dois__()
        -__upload_all_subjects_matched_to_wikidata__()
        +start()
        }

        class WikipediaPageReference
        {
        +title: str = None
        }
    }

    class WikimediaEventStream
    {
    +earlier_events: Set[str] = set()
    +event_count: int = 0
    +event_site: WikimediaSite = None
    +language_code: str = None
    +missing_dois: List[Doi] = None
    +missing_identitifier_limit: int = config.missing_identitifier_limit
    +pywikibot_site: PywikibotSite = None
    +total_number_of_dois: int = 0
    +total_number_of_isbn: int = 0
    +total_number_of_missing_dois: int = 0
    +total_number_of_missing_isbn: int = 0
    -__get_events__()
    -__init__()
    -__instantiate_pywikibot__()
    -__print_missing_dois__()
    -__print_sourcemd_link__()
    -__print_statistics__()
    }

    class WikimediaEvent
    {
    +bot_edit: bool
    +edit_type: WikimediaEditType = None
    +event_data: Dict[str, str] = None
    +event_stream: Any = None  # We can't type this because of pydantic
    +language_code: str = None
    +namespace: int = None
    +page_title: str = None
    +server_name: str = None
    +wikipedia_page: WikipediaPage = None
    -__init__()
    -__parse__()
    -__print_progress__()
    +process()
    +url()
    }
}

package crossref_engine {
    class CrossrefEngine
    {
    +data: Any = None
    +object_type: str = None
    +result: Any = None
    +wikipedia_doi: str
    +work: CrossrefWork = None
    -__convert_to_snake_case__()
    -__lookup_work__()
    -__parse_habanero_data__()
    +lookup_work()
    +match_subjects()
    }

    class CrossrefWork
    {
    -__isbn: Optional[List[str]]
    -__license_url: Optional[str]
    +author: Optional[List[CrossrefAuthor]]
    +doi: str
    +is_referenced_by_count: Optional[conint(ge=0)]
    +issn: Optional[List[str]]
    +issn_qid: Optional[str]
    +issued: Optional[CrossrefDateParts]
    +link: Optional[List[CrossrefLink]]
    +named_entity_recognition: NamedEntityRecognition = None
    +object_type: Optional[CrossrefEntryType]
    +original_title: Optional[List[str]]
    +pdf_urls: Optional[List[str]]
    +prefix: Optional[str]
    +published: Optional[CrossrefDateParts]
    +published_print: Optional[CrossrefDateParts]
    +publisher: Optional[str]
    +publisher_location: Optional[str]
    +reference: Optional[List[CrossrefReference]]
    +references_count: Optional[conint(ge=0)]
    +score: str
    +source: str
    +subject: Optional[List[str]]  # raw subjects
    +subtitle: Optional[List[str]]
    +title: Optional[List[Any]]
    +first_title
    +isbn_list
    +license_qid
    +number_of_subject_matches
    +references

    +raw_subjects: Optional[List[str]]
    +already_matched_qids: List[str] = None
    +subject_matches: List[FuzzyMatch] = None
    -__lookup_subjects__()
    -__str__()
    +match_subjects_to_qids()
    +parse_into_objects()
    +pretty_print()
    }
}
PickledDataframe <|- Matches
PickledDataframe <|- Statistics
Identifier <|- Doi
Item <|- ScientificItem
WikipediaPageReference <|- CiteJournal
BaseModel <|- WikipediaPage
BaseModel <|- CrossrefEngine
BaseModel <|- CrossrefWork
BaseModel <|- Item
BaseModel <|- PickledDataframe
BaseModel <|- Identifier
BaseModel <|- EntityId
BaseModel <|- WikimediaEventStream
BaseModel <|- WikimediaEvent
BaseModel <|- WikipediaPageReference
BaseModel <|- FuzzyMatch
BaseModel <|- OntologyBasedNerMatcher
'BaseModel <|-

WikipediaPage "0..*" - "1..*" Doi
WikipediaPage "0..*" - "1..*" CiteJournal
ScientificItem "0..*" - "1..*" FuzzyMatch
ScientificItem "0..*" - "1" CrossrefEngine
CrossrefEngine "0..*" - "1" CrossrefWork
Doi "0..*" - "1" ScientificItem
PickledDataframe "0..*" - "1" FuzzyMatch
OntologyBasedNerMatcher "0..*" - "1" FuzzyMatch
CrossrefWork "0..*" - "1..*" FuzzyMatch
FuzzyMatch "1" - "1" EntityId

enum MatchStatus
enum PywikibotSite
enum OntologyDataframeColumn
enum MatchBasedOn
enum CacheDataframeColumn

'enum TimeUnit {
'DAYS
'HOURS
'MINUTES
'}

@enduml